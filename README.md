# ğŸ¤ ConsultDeck Studio
### GitHub â†’ RAG â†’ Voice Q&A Presentation System

> Paste your GitHub repo URL, upload your slides, and your presentation becomes a **live AI expert** that answers client questions â€” by voice, in English or Hindi.

---

## ğŸ§  How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ConsultDeck Studio                        â”‚
â”‚                                                             â”‚
â”‚  Step 1: You paste your GitHub repo URL                     â”‚
â”‚          â†“                                                  â”‚
â”‚  Step 2: System auto-fetches ALL files (code, docs, README) â”‚
â”‚          â†“                                                  â”‚
â”‚  Step 3: Files are chunked â†’ embedded â†’ stored in ChromaDB  â”‚
â”‚          â†“                                                  â”‚
â”‚  Step 4: You present your slides to client                  â”‚
â”‚          â†“                                                  â”‚
â”‚  Step 5: Client asks a question (voice or text)             â”‚
â”‚     â†’ Whisper transcribes speech                           â”‚
â”‚     â†’ RAG retrieves relevant code/docs                     â”‚
â”‚     â†’ LLM generates slide-aware answer                     â”‚
â”‚     â†’ TTS speaks the answer aloud                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ¨ Features

| Feature | Detail |
|---|---|
| ğŸ”— **GitHub Ingestion** | Paste any public/private repo URL â†’ all files auto-indexed |
| ğŸ§  **Slide-Scoped RAG** | Each slide activates relevant context from your codebase |
| ğŸ¤ **Voice Input** | Client asks questions verbally â€” Whisper understands both EN + HI |
| ğŸ”Š **Voice Output** | AI answers spoken aloud via OpenAI TTS |
| ğŸ‡®ğŸ‡³ **Hindi Support** | Full Hinglish/Hindi Q&A supported |
| ğŸ”’ **Self-Hosted** | Your repo data never leaves your infrastructure |
| ğŸ¤– **Multi-Provider** | OpenAI / Claude / Ollama (local) |

---

## ğŸš€ Quick Start

### 1. Clone & Configure

```bash
git clone https://github.com/YOUR_USERNAME/consultdeck-studio.git
cd consultdeck-studio

# Configure environment
cp backend/.env.example backend/.env
# Edit backend/.env â€” add your OPENAI_API_KEY at minimum
```

### 2. Start with Docker (Recommended)

```bash
docker compose up -d

# Open browser
open http://localhost:3000
```

### 3. Or Run Locally

```bash
# Terminal 1 â€” Backend
cd backend
python -m venv venv && source venv/bin/activate
pip install -r requirements.txt
cp .env.example .env    # fill in your keys
uvicorn main:app --reload --port 8000

# Terminal 2 â€” Frontend
cd frontend
npm install
BACKEND_URL=http://localhost:8000 npm run dev
```

---

## ğŸ¯ Usage Flow

### As a Consultant (Setup)

1. Open `http://localhost:3000`
2. Paste your GitHub repo URL (e.g. your RAG system repo)
3. Click **"Fetch & Index Repo"** â€” wait for green âœ…
4. Choose AI provider
5. Click **"Launch Presentation â†’"**

### During Client Presentation

- Slides show on the main screen
- **Voice Q&A panel** is always visible (bottom-right)
- Client (or you) clicks mic â†’ asks question
- AI answers in real-time with voice
- Language toggle: **EN / à¤¹à¤¿** (switch anytime)
- Press **V** to toggle voice panel visibility

---

## ğŸ—ï¸ Architecture

```
consultdeck-studio/
â”œâ”€â”€ backend/                    # Python FastAPI
â”‚   â”œâ”€â”€ main.py                 # Entry point
â”‚   â”œâ”€â”€ config.py               # Settings (reads .env)
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ ingest.py           # /api/ingest/github, /api/ingest/slide
â”‚   â”‚   â”œâ”€â”€ rag.py              # /api/rag/query
â”‚   â”‚   â””â”€â”€ voice.py            # /api/voice/transcribe, /api/voice/speak
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ github_fetcher.py   # GitHub API â†’ fetch all files
â”‚   â”‚   â”œâ”€â”€ vector_store.py     # ChromaDB operations
â”‚   â”‚   â”œâ”€â”€ rag_service.py      # Query + LLM answer generation
â”‚   â”‚   â””â”€â”€ voice_service.py    # Whisper STT + OpenAI TTS
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ schemas.py          # Pydantic request/response models
â”‚
â”œâ”€â”€ frontend/                   # Next.js 14
â”‚   â””â”€â”€ src/app/
â”‚       â”œâ”€â”€ page.tsx            # Studio setup page
â”‚       â”œâ”€â”€ present/page.tsx    # Presentation + Voice overlay
â”‚       â”œâ”€â”€ hooks/
â”‚       â”‚   â””â”€â”€ useVoiceRAG.ts  # Core voice pipeline hook
â”‚       â”œâ”€â”€ components/voice/
â”‚       â”‚   â””â”€â”€ VoicePanel.tsx  # Voice Q&A UI widget
â”‚       â””â”€â”€ api/[...path]/      # Proxy to Python backend
â”‚
â””â”€â”€ docker-compose.yml
```

---

## ğŸ”§ Configuration

### AI Providers

| Provider | STT | TTS | RAG | Best For |
|---|---|---|---|---|
| **OpenAI** | Whisper âœ… | TTS-1 âœ… | GPT-4o âœ… | Best quality |
| **Anthropic** | Whisper âœ… | TTS-1 âœ… | Claude âœ… | Best reasoning |
| **Ollama** | Browser API | Browser API | Llama 3.1 | Offline / private |

### For Private GitHub Repos

```env
GITHUB_TOKEN=ghp_your_token_here
```

### Supported File Types (auto-indexed)

`.py` `.ts` `.js` `.tsx` `.md` `.yaml` `.json` `.sql` `.ipynb` `.tf` `.sh` `.dockerfile` `.java` `.go` `.rs` + more

---

## ğŸ—ºï¸ Roadmap

- [ ] Slide upload via PPTX/PDF parsing
- [ ] Multi-session dashboard
- [ ] ElevenLabs voice integration
- [ ] Real-time waveform visualization
- [ ] Export Q&A transcript as PDF

---

## ğŸ“„ License

MIT

---

<p align="center">Built for consultants who want their slides to talk back.</p>
